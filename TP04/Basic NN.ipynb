{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1-Layer Neural Network (Multi-Layer-Perceptron)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Create a complicated dataset ---#\n",
    "from sklearn.datasets import make_moons\n",
    "(X,y) = make_moons(n_samples=500, shuffle=True, noise=0.1)\n",
    "\n",
    "#--- Visualize ---#\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(X[y==0,0],X[y==0,1],'.b')\n",
    "plt.plot(X[y==1,0],X[y==1,1],'.r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Perceptron Parameters ---#\n",
    "perceptron_NHidden = 2000\n",
    "batchSize = 128\n",
    "epochs=500\n",
    "nonlinearity = 'tanh'\n",
    "\n",
    "#--- Create a Perceptron ---#\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# Add a Dense layer and an Output layer\n",
    "snn = Sequential()\n",
    "snn.add(Dense(perceptron_NHidden, input_dim=2, activation=nonlinearity))\n",
    "snn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Decide on the metrics for the model\n",
    "snn.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit to the training data\n",
    "p_history = snn.fit(X, y, epochs=epochs, batch_size=batchSize, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Visualize Decision Boundary ---#\n",
    "n = 250\n",
    "hdom = np.linspace(-2,3,n) \n",
    "vdom = np.linspace(-2,3,n) \n",
    "HH, VV  = np.meshgrid(hdom,vdom)\n",
    "\n",
    "XPred = np.c_[HH.ravel(), VV.ravel()]\n",
    "yPred = snn.predict(XPred)\n",
    "yTrain = snn.predict(X).ravel()\n",
    "yTrainC = yTrain > 0.5\n",
    "\n",
    "yPred = np.reshape(yPred,(n,n))\n",
    "\n",
    "# Prediction Figure\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(yPred, cmap='RdBu_r', origin='lower', extent=(-2, 3, -2, 3))\n",
    "plt.plot(X[y==0,0],X[y==0,1],'ob',alpha=0.5)\n",
    "plt.plot(X[y==1,0],X[y==1,1],'or', alpha=0.5)\n",
    "plt.title('Prediction', fontsize=18)\n",
    "\n",
    "# Decision Boundary Figure\n",
    "plt.subplot(132)\n",
    "plt.imshow(yPred > 0.5, cmap='bwr', origin='lower', extent=(-2, 3, -2, 3))\n",
    "plt.plot(X[np.not_equal(y,yTrainC),0],X[np.not_equal(y,yTrainC),1],'xk', markeredgecolor='k')\n",
    "plt.title('Decision Boundary', fontsize=18)\n",
    "\n",
    "# Final Training Prediction\n",
    "plt.subplot(133)\n",
    "plt.scatter(X[:,0],X[:,1],c=yTrain, cmap='bwr')\n",
    "plt.title('Training Prediction', fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#--- Display Final Test Error ---#\n",
    "training_error = np.mean(np.not_equal(y,yTrainC))\n",
    "print('--------\\nTraining Error = %0.2f%%\\n--------' % (training_error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network with Depth\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- MLP Parameters ---#\n",
    "mlp_NHidden = (10,10,10,10)\n",
    "batchSize = 32\n",
    "epochs=500\n",
    "layers = len(mlp_NHidden)\n",
    "nonlinearity = 'tanh'\n",
    "\n",
    "#--- Create a Perceptron ---#\n",
    "# Add a Dense layer and an Output layer\n",
    "MLP = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "MLP.add(Dense(mlp_NHidden[0], input_dim=2, activation=nonlinearity))\n",
    "\n",
    "# Add remaining intermediate layers\n",
    "for l in range(1,layers):\n",
    "    MLP.add(Dense(mlp_NHidden[l], activation=nonlinearity))\n",
    "\n",
    "# Add final layer\n",
    "MLP.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Decide on the metrics for the model\n",
    "MLP.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit to the training data\n",
    "mlp_history = MLP.fit(X, y, epochs=epochs, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Visualize Decision Boundary ---#\n",
    "n = 250\n",
    "hdom = np.linspace(-2,3,n) \n",
    "vdom = np.linspace(-2,3,n) \n",
    "HH, VV  = np.meshgrid(hdom,vdom)\n",
    "\n",
    "XPred = np.c_[HH.ravel(), VV.ravel()]\n",
    "yPred = MLP.predict(XPred)\n",
    "yTrain = MLP.predict(X).ravel()\n",
    "yTrainC = yTrain > 0.5\n",
    "\n",
    "yPred = np.reshape(yPred,(n,n))\n",
    "\n",
    "# Prediction Figure\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(yPred, cmap='RdBu_r', origin='lower', extent=(-2, 3, -2, 3))\n",
    "plt.plot(X[y==0,0],X[y==0,1],'ob',alpha=0.5)\n",
    "plt.plot(X[y==1,0],X[y==1,1],'or', alpha=0.5)\n",
    "plt.title('Prediction', fontsize=18)\n",
    "\n",
    "# Decision Boundary Figure\n",
    "plt.subplot(132)\n",
    "plt.imshow(yPred > 0.5, cmap='bwr', origin='lower', extent=(-2, 3, -2, 3))\n",
    "plt.plot(X[np.not_equal(y,yTrainC),0],X[np.not_equal(y,yTrainC),1],'xk', markeredgecolor='k')\n",
    "plt.title('Decision Boundary', fontsize=18)\n",
    "\n",
    "# Final Training Prediction\n",
    "plt.subplot(133)\n",
    "plt.scatter(X[:,0],X[:,1],c=yTrain, cmap='bwr')\n",
    "plt.title('Training Prediction', fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#--- Display Final Test Error ---#\n",
    "training_error = np.mean(np.not_equal(y,yTrainC))\n",
    "print('--------\\nTraining Error = %0.2f%%\\n--------' % (training_error*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Comparison ---#\n",
    "perceptron_nparams = 2*perceptron_NHidden + perceptron_NHidden + perceptron_NHidden + 1\n",
    "mlp_nparams = 0\n",
    "for layer in MLP.layers:\n",
    "    # Sum together  weights------------------------      and biases ------------------------\n",
    "    #                         /                    \\                    /                   \\\n",
    "    mlp_nparams += np.asarray(layer.get_weights()[0]).size + np.asarray(layer.get_weights()[1]).size\n",
    "    \n",
    "\n",
    "\n",
    "p_training_err = 1 - np.asarray(p_history.history['acc'])\n",
    "mlp_training_err = 1 - np.asarray(mlp_history.history['acc'])\n",
    "\n",
    "p_training_nacc = np.asarray(p_history.history['acc']) / perceptron_nparams\n",
    "mlp_training_nacc = np.asarray(mlp_history.history['acc']) / mlp_nparams\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(p_training_err,   label='Perceptron')\n",
    "plt.plot(mlp_training_err, label='MLP')\n",
    "plt.xlabel('Training Epochs', fontsize=16)\n",
    "plt.ylabel('Training Error', fontsize=16)\n",
    "plt.xlim((0,epochs-1))\n",
    "plt.legend(loc=1, fontsize=16)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(p_training_nacc,   label='Perceptron')\n",
    "plt.plot(mlp_training_nacc, label='MLP')\n",
    "plt.xlabel('Training Epochs', fontsize=16)\n",
    "plt.ylabel('Per-Model-Parameter Accuracy', fontsize=16)\n",
    "plt.xlim((0,epochs-1))\n",
    "plt.legend(loc=4, fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print('1-Layer # Parmeters:    ', perceptron_nparams)\n",
    "print('Deep Model # Parmeters: ', mlp_nparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Encoder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Auto Encoder Parameters ---#\n",
    "batchSize = 128\n",
    "epochs = 1024\n",
    "\n",
    "#--- Create a Perceptron ---#\n",
    "# Add a Dense layer and an Output layer\n",
    "MLP = Sequential()\n",
    "\n",
    "\n",
    "MLP.add(Dense(60, input_dim=2, activation=nonlinearity))\n",
    "\n",
    "MLP.add(Dense(20, activation='relu'))\n",
    "\n",
    "MLP.add(Dense(1, activation='relu'))\n",
    "\n",
    "MLP.add(Dense(20, activation='relu'))\n",
    "\n",
    "MLP.add(Dense(60, activation='relu'))\n",
    "\n",
    "# Add final layer\n",
    "MLP.add(Dense(2, activation='linear'))\n",
    "\n",
    "# Decide on the metrics for the model\n",
    "MLP.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse'])\n",
    "\n",
    "# Fit to the training data\n",
    "X = X[np.random.permutation(X.shape[0]),:]\n",
    "mlp_history = MLP.fit(X, X, epochs=epochs, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xout = MLP.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(X[:,0],X[:,1],'.b')\n",
    "plt.plot(Xout[:,0],Xout[:,1],'or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder = Sequential()\n",
    "decoder.add(Dense(20, input_dim=1, activation='relu'))\n",
    "decoder.add(Dense(60, activation='relu'))\n",
    "decoder.add(Dense(2, activation='linear'))\n",
    "\n",
    "decoder.layers[0].set_weights(MLP.layers[3].get_weights())\n",
    "decoder.layers[1].set_weights(MLP.layers[4].get_weights())\n",
    "decoder.layers[2].set_weights(MLP.layers[5].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = decoder.predict(np.linspace(-5,5,400))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(X[:,0],X[:,1],'.b')\n",
    "plt.plot(Z[:,0], Z[:,1], '-', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
