{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_lfw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classification of Faces\n",
    "----\n",
    "\n",
    "Face classification is a common problem in computer vision. From Facebook to airports, identifying individuals automatically has many possible utilities. In this notebook we are going to use this application as test-case for 2D convolutional neural networks (CNNs). \n",
    "\n",
    "It has been known for a long time that face classification is not a *difficult* problem, at least compared to general-case object recognition and unconstrained image classification. Identifying face regions in an image takes a bit of work, but the geometrical face structure is a very regular, and can be modelled very well just through principal component analysis (PCA). By projecting onto a low-dimensional space, it becomes practical to train classifiers via logistic regression or support vector machines (SVM). Often this soves the problem quite well.\n",
    "\n",
    "Using CNNs for this task is a bit of overkill, but it gives us a problem that we can easily work on with limited training data, limited training horsepower (laptops in $<$10 min), and still get a reasonable result.\n",
    "\n",
    "We are going to work with a dataset called `Labelled Faces in the Wild` (LFW). [You can find the full description of the dataset here](http://vis-www.cs.umass.edu/lfw/). Also, you will need to download the dataset (~100Mb) and store it on your HDD. The version of the dataset we wish to use is the **Deep Funneled** version which contains pre-aligned and centered images of the faces. This helps us avoid a lot of messy pre-processing. \n",
    "\n",
    "* [Download Link for **Deep Funneled** LFW Dataset.](http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz)\n",
    "\n",
    "We have prepared a function which already takes care of the data-loading and formatting. We will work with a small subset of the dataset, one containing only individuals for which more than ~50 face images exist. This reduces the amount of data to work with. \n",
    "\n",
    "Additionally, the original images are of size $250\\times 250$ pixels. This is a bit larger than we want to work with on our laptops, so we scale the images down to a size of $125\\times 125$ pixels. The loading function also applys a shuffling of the dataset, so we set the state of the random number generator (kwarg `random_state`) so that we all get close to the same results for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Load our LFW Data ---#\n",
    "(X, y, names) = load_lfw_dataset(min_num_faces=49, scale=0.5, data_home='./mldata', random_state=42)\n",
    "print('Dataset Dimensions: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lets take a look at the dataset in an abbreviated fashion. This is just for fun and to get an idea of the data. We'll make a portrait of each individual in the dataset by a simple averaging of their images display the resulting mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- View People in Dataset ---#\n",
    "num_people = len(names)\n",
    "\n",
    "L = int(np.sqrt(num_people)) + 1\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(0,num_people):\n",
    "    plt.subplot(L,L,i+1)\n",
    "    plt.imshow(np.mean(X[y==i, :, :, :], axis=0))\n",
    "    plt.title(names[i], fontsize=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "An important facet of effective practical ML is to focus on known predictive features. In this case, we want to have a model which is focused on classifying *faces*, not the background. So, we can reduce the complexity of our model by taking a center crop of the face images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Crop to Faces ---#\n",
    "# Get crop dimensions\n",
    "vert_dim  = X.shape[1]\n",
    "horz_dim  = X.shape[2] \n",
    "horz_crop = (int(0.2*horz_dim), int(0.8*horz_dim))\n",
    "vert_crop = (int(0.08*vert_dim), int(0.84*vert_dim))   \n",
    "# Make crop\n",
    "X = X[:, vert_crop[0]:vert_crop[1], horz_crop[0]:horz_crop[1], :]\n",
    "print('Dataset Dimensions: ', X.shape)\n",
    "# Save this new dimension\n",
    "img_dim = (X.shape[1], X.shape[2], 3)\n",
    "\n",
    "#--- Display ---#\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(0,num_people):\n",
    "    plt.subplot(L,L,i+1)\n",
    "    plt.imshow(np.mean(X[y==i, :, :, :], axis=0))\n",
    "    plt.title(names[i], fontsize=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now lets go ahead and make a train-test split and set aside some test data in order to compare our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
    "\n",
    "print('Train Dataset Shape: ', X.shape)\n",
    "print('Test Dataset Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, lets take a look at what we can know about this dataset in the simplest possible way. This is just to get an idea of the main axes that separate images from one another. We can do this by looking at the principal components (PC) of the dataset (e.g. the PCA). To do this, we first need to flatten the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Take a look at the PCA ---#\n",
    "def flatten(X):\n",
    "    XFlat = np.empty((X.shape[0], X.shape[1]*X.shape[2]*X.shape[3]), dtype=float)\n",
    "    for i in range(X.shape[0]):\n",
    "        XFlat[i,:] = np.squeeze(X[i, :, :, :]).ravel() \n",
    "    \n",
    "    return XFlat\n",
    "    \n",
    "\n",
    "XFlat = flatten(X)\n",
    "XFlat_test = flatten(X_test)\n",
    "\n",
    "print('Flattened Dimensions: ', XFlat.shape)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can use Scikit-Learn to find the PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#--- Calculate PCA Transform ---#\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(XFlat)\n",
    "# Find projection of dataset onto PCs\n",
    "XPCA = pca.transform(XFlat)\n",
    "# Find values of the PCs themselves\n",
    "PCS = pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lets take a look at what the PCs are. Since these PCs are generated from an SVD, these are essentially orthogonal basis vectors which best describe the variation in the dataset. Additionally, scikit-learn gives the components in an ordered fashion, e.g. the first PC is the vector which describes the maximal direction of variation in the dataset. Below we plot the top 25 PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    comp = PCS[i,:]\n",
    "    comp = (comp - np.min(comp)) / (np.max(comp) - np.min(comp))\n",
    "    plt.imshow(np.reshape(comp,(95,75,3)))\n",
    "    plt.title('PC %s' % str(i+1), fontsize=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, just looking at these PCs don't tell us very much. However, what we can do is to look at the projection of the LFW dataset onto these top principal components. We can then rank the dataset based on the ordering of these components. Some face images may have large positive or negative values when projected onto a particular PC. Looking at the largest and smallest scores of the dataset against the PC then tells us something about the seperation along the PC.\n",
    "\n",
    "Below we show the top 10 PCs, and the largest and smallest scoring dataset images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "top_show = 3\n",
    "pc_show  = 10\n",
    "pltcnt = 1\n",
    "for pc in range(pc_show):\n",
    "    top_scoring = np.argsort(XPCA[:, pc])[-top_show:]\n",
    "    bot_scoring = np.argsort(XPCA[:, pc])[top_show:]\n",
    "\n",
    "    # Show PC\n",
    "    plt.subplot(pc_show, (2*top_show)+1, pltcnt)  \n",
    "    comp = PCS[pc,:]\n",
    "    comp = (comp - np.min(comp)) / (np.max(comp) - np.min(comp))\n",
    "    plt.imshow(np.reshape(comp,img_dim))\n",
    "    plt.title('PC %s' % str(pc+1), fontsize=16)\n",
    "\n",
    "    pltcnt+=1\n",
    "    # Show hi-scoring\n",
    "    for i in range(top_show):\n",
    "        plt.subplot(pc_show, (2*top_show)+1, pltcnt)    \n",
    "        plt.imshow(X[top_scoring[i], :, :, :])\n",
    "        plt.title('Hi Score # %s' % str(i+1), fontsize=16)\n",
    "        pltcnt+=1\n",
    "        \n",
    "    for i in range(top_show):\n",
    "        plt.subplot(pc_show, (2*top_show)+1, pltcnt)    \n",
    "        plt.imshow(X[bot_scoring[i], :, :, :])\n",
    "        plt.title('Lo Score # %s' % str(i+1), fontsize=16)\n",
    "        pltcnt+=1        \n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#--- Fit the Perceptron ---#\n",
    "mlr = LogisticRegression(solver='sag', max_iter=1000, multi_class='multinomial')\n",
    "mlr.fit(XPCA, y)\n",
    "\n",
    "#--- Transform and predict test data ---#\n",
    "ypred = mlr.predict(pca.transform(XFlat_test))\n",
    "\n",
    "#--- Show results on test data ---#\n",
    "print(classification_report(y_test, ypred, target_names=names))\n",
    "\n",
    "#--- Calculate Confusion Matrix ---#\n",
    "cmat = confusion_matrix(y_test, ypred).astype(np.float)\n",
    "# Normalization...\n",
    "for i in range(cmat.shape[0]):\n",
    "    cmat[i,:] = cmat[i,:] / np.sum(cmat[i,:])\n",
    "# Display...\n",
    "plt.figure(figsize=(10,10))    \n",
    "plt.imshow(cmat, vmin=0, vmax=1, cmap='Blues') \n",
    "plt.yticks(range(len(names)),names)\n",
    "plt.xticks(range(len(names)),names,rotation='vertical')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So, as we can see, we are able to get a pretty adequate level of classification perfomance just from a multinomial logistic regression on the top 100 principal component features. This is a simple approach that gives us an effective classifier. Now the question remains, can we do much better? Certainly there are other approaches we could use (CARTS, Boosting, etc.) for the classification/regression. However, lets take this opportunity to apply CNNs to this image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CNNs for Face Classification\n",
    "---\n",
    "\n",
    "Now lets take a look at using a CNN for this same task. For some great references on CNN design, see\n",
    "\n",
    "* [Stanford CNNs for Visual Recog Class](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "We will explain the structure of CNNs and how they can be applied to images on the blackboard. In this notebook, we will focus on one particular structure and then leave it as an exercise to attempt to boost it. Our initial structure will be:\n",
    "\n",
    "* **[Input] -> [Conv -> ReLu -> Conv -> ReLu -> MaxPool]x2 -> Dense -> ReLu -> Dropout -> Labels **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "input_dim = (X.shape[1], X.shape[2], X.shape[3])\n",
    "#--- Network Structure ---#\n",
    "faceNet = Sequential()\n",
    "\n",
    "# First Convolution Block\n",
    "faceNet.add(Conv2D(32, \n",
    "                   kernel_size=(3,3), \n",
    "                   data_format='channels_last', \n",
    "                   input_shape=input_dim, \n",
    "                   activation='relu'))\n",
    "faceNet.add(Conv2D(32, \n",
    "                   kernel_size=(3,3), \n",
    "                   activation='relu'))\n",
    "faceNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# Second Convolution Block\n",
    "faceNet.add(Conv2D(32, \n",
    "                   kernel_size=(3,3), \n",
    "                   activation='relu'))\n",
    "faceNet.add(Conv2D(32, \n",
    "                   kernel_size=(3,3), \n",
    "                   activation='relu'))\n",
    "faceNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# To Fully Connected Layer\n",
    "faceNet.add(Flatten())\n",
    "faceNet.add(Dense(128, activation='relu'))\n",
    "faceNet.add(Dropout(0.2))\n",
    "\n",
    "# Final Labels\n",
    "faceNet.add(Dense(num_people, activation='softmax'))\n",
    "\n",
    "#--- Training ---#\n",
    "# Set Parameters\n",
    "faceNet.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Get class weights\n",
    "class_counts = np.histogram(y, bins=num_people)[0]\n",
    "class_weight = class_counts / np.max(class_counts)\n",
    "\n",
    "# Run Training\n",
    "train_history = faceNet.fit(X, to_categorical(y), validation_split=0.05, epochs=10, verbose=1, batch_size=32, class_weight=class_weight)\n",
    "\n",
    "# Save model parameters\n",
    "faceNet.save('faceNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ypred = faceNet.predict(X_test)\n",
    "ypred = faceNet.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Show results on test data ---#\n",
    "print(classification_report(y_test, ypred, target_names=names))\n",
    "\n",
    "#--- Calculate Confusion Matrix ---#\n",
    "cmat = confusion_matrix(y_test, ypred).astype(np.float)\n",
    "# Normalization...\n",
    "for i in range(cmat.shape[0]):\n",
    "    cmat[i,:] = cmat[i,:] / np.sum(cmat[i,:])\n",
    "# Display...\n",
    "plt.figure(figsize=(10,10))    \n",
    "plt.imshow(cmat, vmin=0, vmax=1, cmap='Blues') \n",
    "plt.yticks(range(len(names)),names)\n",
    "plt.xticks(range(len(names)),names,rotation='vertical')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now lets take a look at what we missed. It is often illuminating to understand the kinds of features common to the mistaken samples. In this case, we shouldn't fine tune our approach since we are looking at the errors on the *test* set. However, academically, we can see that many of these images exhibit atypical features. For example, a person wearing an uncommon clothing item, having a portion of their face obscured, unusal lighting or angles, or even just mislabeled/aligned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_errors = np.where(np.not_equal(y_test, ypred))[0]\n",
    "L = int(len(test_errors) / 5) + 1\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "pltidx = 1\n",
    "\n",
    "def add_subplot_axes(ax,rect,axisbg='w'):\n",
    "    fig = plt.gcf()\n",
    "    box = ax.get_position()\n",
    "    width = box.width\n",
    "    height = box.height\n",
    "    inax_position  = ax.transAxes.transform(rect[0:2])\n",
    "    transFigure = fig.transFigure.inverted()\n",
    "    infig_position = transFigure.transform(inax_position)    \n",
    "    x = infig_position[0]\n",
    "    y = infig_position[1]\n",
    "    width *= rect[2]\n",
    "    height *= rect[3]  # <= Typo was here\n",
    "    subax = fig.add_axes([x,y,width,height],axisbg=axisbg)\n",
    "    x_labelsize = subax.get_xticklabels()[0].get_size()\n",
    "    y_labelsize = subax.get_yticklabels()[0].get_size()\n",
    "    x_labelsize *= rect[2]**0.5\n",
    "    y_labelsize *= rect[3]**0.5\n",
    "    subax.xaxis.set_tick_params(labelsize=x_labelsize)\n",
    "    subax.yaxis.set_tick_params(labelsize=y_labelsize)\n",
    "    return subax\n",
    "\n",
    "for i in range(len(test_errors)):\n",
    "    test_id = test_errors[i]\n",
    "    im = np.empty((1, X_test.shape[1], X_test.shape[2], X_test.shape[3]), dtype=float)\n",
    "    im[0,:,:,:] = X_test[test_id, :, :, :]\n",
    "    \n",
    "    ax = plt.subplot(L, 5, pltidx)\n",
    "    plt.imshow(X_test[test_id, :, :, :])\n",
    "    plt.title(names[ypred[test_id]])\n",
    "    sax = add_subplot_axes(ax, [0.2, 0.0, 0.7, 0.2])\n",
    "    sax.bar(range(num_people),faceNet.predict(im).ravel(), color='b', edgecolor='w')\n",
    "    sax.axis('off')\n",
    "    \n",
    "    pltidx += 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
